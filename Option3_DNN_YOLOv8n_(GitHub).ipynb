{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWDQe9W+n7Ka0u6NB9Eg1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BumaranChe/Animal_Faces_Detection_Projects/blob/main/Option3_DNN_YOLOv8n_(GitHub).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Download the class names file (coco.names)"
      ],
      "metadata": {
        "id": "y0VUgv7OiJOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O coco.names https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFvc8va0S67a",
        "outputId": "ddcaf665-fb1a-4607-f814-4a1e20dec49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-14 08:03:18--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: â€˜coco.namesâ€™\n",
            "\n",
            "\rcoco.names            0%[                    ]       0  --.-KB/s               \rcoco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2025-08-14 08:03:19 (37.7 MB/s) - â€˜coco.namesâ€™ saved [625/625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Loads yolov8n pretrained weights (PyTorch) and exports the model to ONNX format (making it ready to use with other runtimes OpenCV -->cv2.dnn)"
      ],
      "metadata": {
        "id": "LMWZlpb7iwIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "model.export(format=\"onnx\", opset=12, dynamic=False, simplify=True, nms=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "t7TdhGQ_mhCn",
        "outputId": "967aa807-8f65-458f-c2fc-d64d069993cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.179 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.64...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.3s, saved as 'yolov8n.onnx' (12.2 MB)\n",
            "\n",
            "Export complete (2.3s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yolov8n.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0 Load YOLO model into OpenCV's DNN module"
      ],
      "metadata": {
        "id": "Smj67UULmPwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ===============================\n",
        "# CONFIG\n",
        "# ===============================\n",
        "ONNX_MODEL = \"yolov8n.onnx\"  # Exported with nms=True\n",
        "COCO_NAMES = \"coco.names\"\n",
        "ANIMAL_CLASSES = ['cat', 'dog', 'cow', 'horse', 'sheep', 'bird']\n",
        "CONF_THRESHOLD = 0.5\n",
        "\n",
        "# ===============================\n",
        "# Load COCO class labels\n",
        "# ===============================\n",
        "with open(COCO_NAMES, \"r\") as f:\n",
        "    classes = [line.strip() for line in f]\n",
        "\n",
        "# ===============================\n",
        "# Prepare folders\n",
        "# ===============================\n",
        "os.makedirs(\"positives\", exist_ok=True)\n",
        "os.makedirs(\"negatives\", exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# Load ONNX YOLO model\n",
        "# ===============================\n",
        "net = cv2.dnn.readNetFromONNX(ONNX_MODEL)\n",
        "\n",
        "# ===============================\n",
        "# Process all JPG images in folder\n",
        "# ===============================\n",
        "for img_name in os.listdir():\n",
        "    if not img_name.lower().endswith(\".jpg\"):\n",
        "        continue\n",
        "\n",
        "    img = cv2.imread(img_name)\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    # Create input blob\n",
        "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (640, 640), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    # YOLOv8 NMS output format: [batch, num_detections, 6]\n",
        "    # Each detection: [x1, y1, x2, y2, score, class_id]\n",
        "    detections = detections[0]  # Remove batch dim\n",
        "\n",
        "    animal_found = False\n",
        "\n",
        "    for det in detections:\n",
        "        score = det[4]\n",
        "        class_id = int(det[5])\n",
        "\n",
        "        if score < CONF_THRESHOLD:\n",
        "            continue\n",
        "\n",
        "        if class_id < len(classes) and classes[class_id] in ANIMAL_CLASSES:\n",
        "            animal_found = True\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, det[:4])\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(img, f\"{classes[class_id]} {score:.2f}\",\n",
        "                        (x1, max(15, y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Save to correct folder\n",
        "    if animal_found:\n",
        "        cv2.imwrite(f\"positives/{img_name}\", img)\n",
        "    else:\n",
        "        cv2.imwrite(f\"negatives/{img_name}\", img)\n",
        "\n",
        "print(\"âœ… Processing completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6dgJhilq5W8",
        "outputId": "ed180810-1a9f-4054-908c-c77b56ac63a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Processing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After loading images in content/ , the image file will be processed and saved into content/positives or content/negatives folder. Based on the testing, this model detection is not working well because some of the background (negative images) save into positive directory (content/positives). In conclusion, this model doesn't work well"
      ],
      "metadata": {
        "id": "cjpGtkzjkaDj"
      }
    }
  ]
}